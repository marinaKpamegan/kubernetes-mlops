# MLOps Kubernetes Project

Ce projet impl√©mente une architecture **MLOps** avec **Kubernetes** pour le d√©ploiement d'un mod√®le de Machine Learning sur l'**Iris Dataset**. Il comprend :
- Un **backend** (API ML) servant des pr√©dictions, d√©ploy√© sous forme de **3 r√©plicas**.
- Un **frontend** interagissant avec l'API.
- Une connexion entre le frontend et l'API via un **service Kubernetes**.
- Les images frontend et backend sont accessibles [ici](https://github.com/marinaKpamegan/mlops): 

---

## üöÄ Installation et D√©ploiement

### 1Ô∏è‚É£ Pr√©requis
Avant de commencer, assurez-vous d'avoir :
- [Docker](https://www.docker.com/get-started)
- [Minikube](https://minikube.sigs.k8s.io/docs/start/)
- [Kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/)

### 2Ô∏è‚É£ Lancer Kubernetes
D√©marrez votre cluster Kubernetes local avec Docker Desktop ou Minikube.

### 3Ô∏è‚É£ Construire les images Docker
Ajoutez les images Docker :
```bash
# Construire les images
docker build -t mlops-server:0.1.0 ./mlops-server
docker build -t mlops-client:latest ./mlops-client
```

### 4Ô∏è‚É£ D√©ployer le backend (API ML)
```bash
kubectl apply -f backend-deployment.yaml
```
V√©rifiez les pods :
```bash
kubectl get pods
```

### 5Ô∏è‚É£ D√©ployer le frontend
```bash
kubectl apply -f deployment.yaml
```
V√©rifiez les services :
```bash
kubectl get services
```

### 6Ô∏è‚É£ Acc√©der √† l'application
Obtenez l'URL du frontend :
```bash
minikube service mlops-client-service --url
```
Ouvrez l'URL dans votre navigateur ! üéâ

---

## üîÑ Tester la Communication
Testez manuellement l'API du backend :
```bash
kubectl port-forward service/mlops-api-service 8000:8000
curl http://localhost:8000/version
```
Vous devriez voir : `{"version": "0.1.0"}`

---

## üìå Nettoyage
Si vous souhaitez supprimer les ressources Kubernetes :
```bash
kubectl delete deployment mlops-server mlops-client
kubectl delete service mlops-api-service mlops-client-service
```





